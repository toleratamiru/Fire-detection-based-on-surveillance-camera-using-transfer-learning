{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af07d1b-277f-428a-9b58-b987132396e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"num GPU's Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a46d7f-d2d3-41a6-ba02-07dac733c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0e17ea-5037-4331-80ed-31bbac344414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, precision_recall_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949feafc-b190-4a14-8726-99ae6d848777",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"D:/Dataset1/Train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9735fe9c-840b-4f20-aa45-dcd03795fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train, val = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=\"D:/Dataset/Train\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=(224, 224),  # we  Adjust for four pre-trained model\n",
    "    shuffle=True,\n",
    "    seed=1337,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    interpolation=\"bilinear\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a05ac3b-ff39-43de-bbdc-b58f88dd1ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.RandomRotation(0.4),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "    tf.keras.layers.RandomContrast(0.2),\n",
    "    tf.keras.layers.RandomBrightness(0.2),\n",
    "    tf.keras.layers.RandomTranslation(0.1, 0.1),\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79185d33-d845-4693-a1ca-120596891c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values (this is necessary for most pre-trained models)\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ea77e-3d51-4660-a054-ed4ff4a6c691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data augmentation and normalization to the training dataset\n",
    "train = train.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "train = train.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded19d17-6f00-484b-a347-77687ccee9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply normalization to the validation dataset (without augmentation)\n",
    "val = val.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390730dd-ce16-43bb-a688-81b9da741ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "# Hyperparameter definitions (adjust these for tuning)\n",
    "optimizer = SGD(learning_rate=0.001)  # we can adjust the learning rate here(0.001 &0.0001)\n",
    "#optimizer = Adam(learning_rate=0.001)  # we can adjust the learning rate here(0.001 &0.0001)\n",
    "batch_size = 32 \n",
    "epochs = 40\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb0298b-6f74-4170-9da0-6a41d9be4bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the base model\n",
    "base_model = VGG19(\n",
    "    include_top=False, \n",
    "    weights='imagenet', \n",
    "    input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036b4ed6-b0ed-4ad5-90af-ce85bfe9c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model.trainable = False\n",
    "# Freeze some layers in the base model\n",
    "num_unfreeze_layers = 5\n",
    "for layer in base_model.layers[:-num_unfreeze_layers]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c5218d-7769-47d1-920e-6e9a94f0c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom layers on top of the base model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # For binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44203ce-3250-4ac9-ab95-a0daedd70bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa85d5ae-26bb-44cf-9d8c-b145e57d358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a383b41c-a7b6-473d-9142-12541ce61db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)  # Monitor validation loss, stop after 5 epochs of no improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bbf4f2-b87a-4ba2-b9fd-1a7769383a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define ModelCheckpoint callback\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='best_fire_detection_VGG19_model9010.h5',  # Path to save the best model\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "    mode='max',  # Save the model with the highest validation accuracy\n",
    "    save_best_only=True  # Only save the best model based on the monitored metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8f9ae0-7cf3-475b-a49e-a54b68443f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG19 = model.fit(\n",
    "    train,\n",
    "    epochs=epochs,  # Adjust epochs as needed\n",
    "    validation_data=val,\n",
    "     callbacks=[early_stopping, model_checkpoint_callback]  # Pass Early Stopping callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9a7a3f-1934-48c1-aafb-0555f6eeb435",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"VGG19_based_fire_detection_40epochs910exp1_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c192450f-f809-432d-9eb9-0c1eb5c171be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(VGG19.history['accuracy'])\n",
    "plt.plot(VGG19.history['val_accuracy'])\n",
    "plt.title('VGG19 Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe808be-6ec5-4686-8f6e-be39512c6b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(VGG19.history['loss'])\n",
    "plt.plot(VGG19.history['val_loss'])\n",
    "plt.title('VGG19 Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.ylim(top=1.2, bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c900a212-797d-44d0-953d-3c3359c69938",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Adjustable parameters\"\"\"\n",
    "model = \"VGG19_based_fire_detection_40epochs910exp1_model.h5\"  # path to model save file\n",
    "result_directory = \"D:/Dataset1/Mobilenetv2/result910\" # test result save directory\n",
    "# paths to positive and negative labeled images\n",
    "pos_path = r\"D:/Dataset1/Tests/Fire\"\n",
    "neg_path = r\"D:/Dataset1/Tests/Non-fire\"\n",
    "prediction_threshold = .5\n",
    "image_size = (224, 224)\n",
    "\"\"\"End adjustable parameters\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8814e15-4f60-42d6-8189-ee2fb2034f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model \n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=\"D:/Dataset1/Tests\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=(224, 224),\n",
    "    shuffle=False,\n",
    "    interpolation=\"bilinear\"\n",
    ")\n",
    "# Apply normalization to the test dataset\n",
    "test_dataset = test_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "#test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "#print(f'Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d224f6a5-065c-4f0b-aa50-d9a4d9dec797",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = []  # list for actual labels\n",
    "predicted = []  # list for predicted labels\n",
    "FalsePos = []  # list for missed image file names to save\n",
    "FalseNeg = []  # list for missed image file names to save\n",
    "ConfidenceScores = []  # list for confidence scores for each prediction\n",
    "\n",
    "# Keras built in evaluation\n",
    "reconstructed_model = keras.models.load_model(model)\n",
    "eval_loss, eval_acc = reconstructed_model.evaluate(test_dataset)\n",
    "print(f\"Evaluation accuracy {eval_acc}, Evaluation loss {eval_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7d7117-b095-4445-b857-42c48c666f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(result_directory, exist_ok=True) # Check result_directory exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5d1de8-ce34-45e6-9c60-e1b9a41a965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import csv\n",
    "for pos_image in os.listdir(pos_path):\n",
    "    image_path = pos_path + \"/\" + pos_image\n",
    "    pos_image = keras.preprocessing.image.load_img(image_path, target_size=image_size)\n",
    "    pos_image = keras.preprocessing.image.img_to_array(pos_image)\n",
    "    pos_image = np.expand_dims(pos_image, axis=0)\n",
    "    prediction = reconstructed_model.predict(pos_image)\n",
    "    actual.append(\"1\")\n",
    "    ConfidenceScores.append(((1 - prediction[0][0] * 100), image_path))\n",
    "    if prediction[0][0] < 0.5:\n",
    "        predicted.append(\"1\")\n",
    "    else:\n",
    "        FalseNeg.append(image_path)\n",
    "        predicted.append(\"0\")\n",
    "\n",
    "for neg_image in os.listdir(neg_path):\n",
    "    image_path = neg_path + \"/\" + neg_image\n",
    "    neg_image = keras.preprocessing.image.load_img(image_path, target_size=image_size)\n",
    "    neg_image = keras.preprocessing.image.img_to_array(neg_image)\n",
    "    neg_image = np.expand_dims(neg_image, axis=0)\n",
    "    prediction = reconstructed_model.predict(neg_image)\n",
    "    actual.append(\"0\")\n",
    "    ConfidenceScores.append(((prediction[0][0] * 100), image_path))\n",
    "    if prediction[0][0] > 0.5:\n",
    "        predicted.append(\"0\")\n",
    "    else:\n",
    "        FalsePos.append(image_path)\n",
    "        predicted.append(\"1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643c5a61-a8ab-4554-9e18-933bc2d705ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import csv\n",
    "# Create CSV with missed image paths\n",
    "with open(os.path.join(result_directory, \"missed.csv\"), \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    for image in FalsePos:\n",
    "        writer.writerow([image])\n",
    "    for image in FalseNeg:\n",
    "        writer.writerow([image])\n",
    "\n",
    "# create CSV with confidence (prediction) scores\n",
    "with open(os.path.join(result_directory, \"ConfidenceScores.csv\"), \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    for score in ConfidenceScores:\n",
    "        writer.writerow(score)\n",
    "# ... (previous code)\n",
    "\n",
    "# After processing all images, check if the lengths are equal\n",
    "if len(actual) != len(predicted):\n",
    "    # Determine which list is shorter\n",
    "    shorter_length = min(len(actual), len(predicted))\n",
    "    # Truncate the longer list to match the shorter one\n",
    "    actual = actual[:shorter_length]\n",
    "    predicted = predicted[:shorter_length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1f9ac5-22fd-4bf9-8ce6-ff506b1e6bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can proceed with creating the confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(actual, predicted)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=[\"No-Fire\", \"Fire\"])\n",
    "cm_display.plot(cmap=\"Blues\")\n",
    "plt.savefig(os.path.join(result_directory, \"CM.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4591c7ca-1ab9-4610-b82b-722caab207a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSV with performance metrics\n",
    "with open(os.path.join(result_directory, \"metrics.csv\"), \"w\", newline=\"\") as file:\n",
    "    file.write(f\"Accuracy: {(metrics.accuracy_score(actual,predicted))}\\n\")\n",
    "    file.write(f\"f1-score: {metrics.f1_score(actual,predicted,pos_label='1')}\\n\")\n",
    "    file.write(f\"Precision: {metrics.precision_score(actual, predicted, pos_label='1')}\\n\")\n",
    "    file.write(f\"Recall: {metrics.recall_score(actual,predicted, pos_label='1')}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e0aae3-47ea-4374-8140-ebcb5b8f90b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {(metrics.accuracy_score(actual,predicted))}\")\n",
    "print(f\"f1-score: {metrics.f1_score(actual,predicted,pos_label='1')}\")\n",
    "print(f\"Precision: {metrics.precision_score(actual, predicted, pos_label='1')}\")\n",
    "print(f\"Recall: {metrics.recall_score(actual,predicted, pos_label='1')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c3ce83-a40f-4df2-9318-6f9c0c32fe41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
